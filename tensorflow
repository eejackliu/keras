def new_biases(shape):
    return tf.truncated_normal(shape, stddev=0.05)
# b=tf.placeholder(tf.float32,shape=[100],name='p')


a=new_biases(img_shape)

session=tf.Session()

session.run(tf.global_variables_initializer())
print session.run(a)
如上面这段程序所示，整个计算图在定义好之后要对计算图中的某一个节点进行操作，无论是执行一个算数操作还是对某个节点进行赋值操作，例如初始化变量tf.truncated_normal(shape, stddev=0.05)
都需要告知并启动tensorflow的session.run 来对节点进行操作如（tf.global_variables_initializer()）如果要读取其中一个节点还需要一次session.run操作
session.run(a)来读取a
a=[True,True,True,False,False]
b=np.array(a)
print  (b==False)  #输出的是取反后的bool矩阵
print  (a==False)   #输出一个False
不知为何
layer_shape = layer2.get_shape()
num_feature = layer_shape[1:]
num_feature=reduce(lambda x,y:x*y,num_feature)
layer_fc= tf.reshape(layer2, [-1, num_feature])
 Failed to convert object of type <type 'list'> to Tensor. Contents: [-1, Dimension(1764)]. Consider casting elements to a supported type.
看上去像layer_fc中的num_feature需要一个tensor类型的数据，但是上面用reduce计算出来的结果是list类型，在加上
num_feature=tf.convert_to_tensor(num_feature)这个之后就正常了
或者用num_feature=layer_shape[1:].num_elements()
这个直接代替上面那一堆，num_elements代替手工计算维度乘积的步骤
https://stackoverflow.com/questions/33610685/in-tensorflow-what-is-the-difference-between-session-run-and-tensor-eval
根据上面这个说法，可以使用tensor.eval()来单独运行某一个tensor的结果。前提是要用tf.InteractiveSession()或者with sess.as_default()来单独
指定一个默认的session来保证图的正常运行

model=keras.applications.mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False,input_shape=(None, None, 3))
这是为了得到mobilenetv2
    m=keras.models.Model(inputs=mobile.input,outputs=[mobile.get_layer('Conv1_relu').output,
                                                      mobile.get_layer('block_2_add').output,
                                                      mobile.get_layer('block_5_add').output,
                                                      mobile.get_layer('block_12_add').output,
                                                      mobile.get_layer('block_14_add').output])
这是为了得到mobilenet运行中的几个输出，input不能写成我们希望的shape但是可以写成待定，这也是醉了。input需要写成mobile.net
keras的padding只有zero padding 如果需要 replicate padding则要按以下例子进行
# x = tf.convert_to_tensor([[[1, 2, 3], [4, 5, 6]],
#                           [[10, 20, 30], [40, 50, 60]]])
#
# x = duplicate_last_row(duplicate_last_col(x))
# with tf.Session() as sess:
#     print(sess.run(x))
# # [[[ 1  2  3  3]
# #   [ 4  5  6  6]
# #   [ 4  5  6  6]]
# #
# #  [[10 20 30 30]
# #   [40 50 60 60]
# #   [40 50 60 60]]]
#
#
# # --------------
# # Using as a Keras Layer:
#
# inputs = Input(shape=(5, 5, 3))
# padded = Lambda(lambda t: duplicate_last_row(duplicate_last_col(t)))(inputs)
#
# model = Model(inputs=inputs, outputs=padded)
# model.compile(optimizer="adam", loss='mse', metrics=['mse'])
# batch = np.random.rand(2, 5, 5, 3)
# x = model.predict(batch, batch_size=2)
if step_per_epoch=0 or train_data give 0 images will cause  AttributeError: ‘ProgbarLogger’ object has no attribute ‘log_values’
如果model输出有3个结果那么 model.compile()中的loss就得传一个［diceloss,diceloss,diceloss］这种list进去，metrics是每个epoch结束后进行validation用的
所以得指定需要拿出输出指定的结果 ，这些结果应该和loss是一样的只不过loss是对应与特定的loss函数，metrics是对应accuracy，好像在model.fit_generate()里面要指定
validation data

tf.keras.models.save_model出现AttributeError: ‘NoneType’ object has no attribute ‘update’ 这个是 model.get_config()报出来的，感觉像是
model的图没法保存，getconfig只能拿到None https://blog.csdn.net/mieleizhi0522/article/details/83057946 这个提示说tensoflow里面不能又动态的量
resize需要接受固定值 把上采样的改成固定值后解决问题
1.13.1使用boline原版1.13代码（这个是用keras写的，其中upsampling用的是github包装过的upsampling（里面是tf.image.resize)这个使用load_model的name——scope可以成功
载入。但是在TFLiteConverter的时候会报AttributeError: 'Node' object has no attribute 'output_masks'
根据https://stackoverflow.com/questions/51821537/attributeerror-node-object-has-no-attribute-output-masks
猜测有可能是因为在主要是keras的环境下用tensorflow，断点加单步发现在（，1,1,256）relu处出错，应该是下一步的上采用问题，在换用keras自带上采样层之后解决问题
使用pip源的tf2.0,keras也是tf.keras但是会在load_model时候遇到 model=tf.keras.models.load_model('dddtrue_weight_dsf.hdf5',custom_objects={'relu6':relu6})  custom_objects=custom_objects)
这种错误inputs.insert(index, constant)  TypeError: an integer is required
还是认为是github实现的resize的问题
直接使用以下的用tf2.0特殊的tflite转换方式也会卡在resize那里，暂时无法解决，只能退回到1.13用全部keras的办法解决问题
## model = tf.keras.models.load_model('dddtrue_weight_dsf.h5')
##
## tf.saved_model.save(model,'tf2')
## model = tf.saved_model.load('tf2')
## concrete_func = model.signatures[
##   tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
##
## converter=tf.lite.TFLiteConverter.from_concrete_function(concrete_func)
## tflite_model = converter.convert()
全部使用keras且upsampling用github实现，load_model是没有问题的，精度也高1%，看起来也顺畅，棋盘效果比较小
